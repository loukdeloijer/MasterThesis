{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "from scipy import stats\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "df = pd.read_csv('Need For Touch_November.csv')\n",
    "\n",
    "df = df[df['Finished'].isin(['Finished', '1'])]\n",
    "df = df[df['Duration (in seconds)'] > '100']\n",
    "df = df.loc[[column for column in df.index if column != 42]]\n",
    "sum([int(val) for val in df['Duration (in seconds)'].loc[2:] if int(val) < 3600])/len(df['Duration (in seconds)'].loc[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#woman\n",
    "HighNFTHuman_hoodieWomen = ['Q70', 'Q71']\n",
    "\n",
    "LowNFTHuman_hoodieWomen = ['Q77', 'Q78']\n",
    "\n",
    "HighNFTAI_hoodieWomen = ['Q32', 'Q33']\n",
    "\n",
    "LowNFTAI_hoodieWomen = ['Q90', 'Q89']\n",
    "\n",
    "    #Jeans\n",
    "\n",
    "HighNFTHuman_jeansWomen = ['Q61', 'Q63']\n",
    "\n",
    "LowNFTHuman_jeansWomen = ['Q66', 'Q67']\n",
    "\n",
    "HighNFTAI_jeansWomen = ['Q29', 'Q30']\n",
    "\n",
    "LowNFTAI_jeansWomen = ['Q84', 'Q85']\n",
    "\n",
    "HighNFTWomenAI = [HighNFTAI_hoodieWomen, HighNFTAI_jeansWomen]\n",
    "LowNFTWomenAI = [LowNFTAI_hoodieWomen, LowNFTAI_jeansWomen]\n",
    "HighNFTWomenHuman = [HighNFTHuman_hoodieWomen, HighNFTHuman_jeansWomen]\n",
    "LowNFTWomenHuman = [LowNFTHuman_hoodieWomen, LowNFTHuman_jeansWomen]\n",
    "\n",
    "HighNFTWomen = [HighNFTWomenAI, HighNFTWomenHuman]\n",
    "LowNFTWomen = [LowNFTWomenAI, LowNFTWomenHuman]\n",
    "\n",
    "\n",
    "#men\n",
    "HighNFTHuman_hoodieMen = ['Q40', 'Q41']\n",
    "\n",
    "LowNFTHuman_hoodieMen = ['Q54', 'Q53']\n",
    "\n",
    "HighNFTAI_hoodieMen = ['Q107', 'Q100']\n",
    "\n",
    "LowNFTAI_hoodieMen = ['Q91', 'Q92']\n",
    "\n",
    "    #Jeans\n",
    "\n",
    "HighNFTHuman_jeansMen = ['Q44', 'Q45']\n",
    "\n",
    "LowNFTHuman_jeansMen = ['Q57', 'Q58']\n",
    "\n",
    "HighNFTAI_jeansMen = ['Q108', 'Q98']\n",
    "\n",
    "LowNFTAI_jeansMen = ['Q94', 'Q95']\n",
    "\n",
    "HighNFTMenAI = [HighNFTAI_hoodieMen, HighNFTAI_jeansMen]\n",
    "LowNFTMenAI = [LowNFTAI_hoodieMen, LowNFTAI_jeansMen]\n",
    "HighNFTMenHuman = [HighNFTHuman_hoodieMen, HighNFTHuman_jeansMen]\n",
    "LowNFTMenHuman = [LowNFTHuman_hoodieMen, LowNFTHuman_jeansMen]\n",
    "\n",
    "HighNFTMen = [HighNFTMenAI, HighNFTMenHuman]\n",
    "LowNFTMen = [LowNFTMenAI, LowNFTMenHuman]\n",
    "\n",
    "HighNFT = [HighNFTMen, HighNFTWomen]\n",
    "LowNFT = [LowNFTMen, LowNFTWomen]\n",
    "\n",
    "\n",
    "\n",
    "#AI guessing part\n",
    "AIQuestionAIMaleHoodieHH = 'Q99'\n",
    "AIQuestionAIMaleHoodieLH = 'Q110'\n",
    "AIQuestionAIMaleJeansHH = 'Q102'\n",
    "AIQuestionAIMaleJeansLH = 'Q109'\n",
    "AIQuestionHumanMaleHoodieHH = 'Q36'\n",
    "AIQuestionHumanMaleHoodieLH = 'Q55'\n",
    "AIQuestionHumanMaleJeansHH = 'Q46'\n",
    "AIQuestionHumanMaleJeansLH = 'Q59'\n",
    "\n",
    "AIQuestionAIFemaleHoodieHH = 'Q64'\n",
    "AIQuestionAIFemaleHoodieLH = 'Q88'\n",
    "AIQuestionAIFemaleJeansHH = 'Q82'\n",
    "AIQuestionAIFemaleJeansLH = 'Q86'\n",
    "AIQuestionHumanFemaleHoodieHH = 'Q72'\n",
    "AIQuestionHumanFemaleHoodieLH = 'Q80'\n",
    "AIQuestionHumanFemaleJeansHH = 'Q81'\n",
    "AIQuestionHumanFemaleJeansLH = 'Q68' \n",
    "\n",
    "AIproductsFemale = [AIQuestionAIFemaleHoodieHH, AIQuestionAIFemaleHoodieLH, AIQuestionAIFemaleJeansHH, AIQuestionAIFemaleJeansLH]\n",
    "AIproductsMale = [AIQuestionAIMaleHoodieHH, AIQuestionAIMaleHoodieLH, AIQuestionAIMaleJeansHH,AIQuestionAIMaleJeansLH]\n",
    "\n",
    "HumanproductsFemale = [AIQuestionHumanFemaleHoodieHH, AIQuestionHumanFemaleHoodieLH, AIQuestionHumanFemaleJeansHH, AIQuestionHumanFemaleJeansLH]\n",
    "HumanproductsMale = [AIQuestionHumanMaleHoodieHH, AIQuestionHumanMaleHoodieLH, AIQuestionHumanMaleJeansHH, AIQuestionHumanMaleJeansLH]\n",
    "\n",
    "AIproducts = AIproductsFemale + AIproductsMale\n",
    "Humanproducts = HumanproductsMale + HumanproductsFemale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_HighNFT = [elem[0] for subsublist  in [item for sublist in HighNFT for item in sublist] for elem in subsublist]\n",
    "Q2_HighNFT = [elem[1] for subsublist  in [item for sublist in HighNFT for item in sublist] for elem in subsublist]\n",
    "Q1_LowNFT = [elem[0] for subsublist  in [item for sublist in LowNFT for item in sublist] for elem in subsublist]\n",
    "Q2_LowNFT = [elem[1] for subsublist  in [item for sublist in LowNFT for item in sublist] for elem in subsublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "hapticDF = df[Q1_HighNFT].loc[2:]\n",
    "NonhapticDF = df[Q1_LowNFT].loc[2:]\n",
    "hapticDF2 = df[Q2_HighNFT].loc[2:]\n",
    "NonhapticDF2 = df[Q2_LowNFT].loc[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hypothesis 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'haptic': 4.185897435897436, 'non-haptic': 4.166666666666667}\n",
      "{'haptic': 1.544206601502019, 'non-haptic': 1.4759724332303479}\n",
      "{'haptic': 4.07051282051282, 'non-haptic': 3.967948717948718}\n",
      "{'haptic': 1.537119969239413, 'non-haptic': 1.4958862808031632}\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "def mean_instruction_types(df1, df2):\n",
    "    names =['haptic', 'non-haptic']\n",
    "    dflist = [df1, df2]\n",
    "\n",
    "    comparisondict = {'df1':dict(), 'df2':dict()}\n",
    "    for dfname, df in list(zip(comparisondict.keys(), dflist)):\n",
    "        for column in df.columns:\n",
    "            comparisondict[dfname][column] = [int(a) for b in [elem for elem in df[column].tolist() if type(elem) != float] for a in b]\n",
    "    \n",
    "    for key in comparisondict.keys():\n",
    "        subdict = comparisondict[key]\n",
    "        comparisondict[key] = sum(subdict.values(), [])\n",
    "    \n",
    "    score_dict = {}\n",
    "    SD_dict = {}\n",
    "    dfnameslist = list(comparisondict.keys())\n",
    "    \n",
    "    for key, alist in list(zip(names, comparisondict.values())):\n",
    "        score_dict[key] = statistics.mean(alist)\n",
    "        SD_dict[key] = statistics.stdev(alist)\n",
    "        \n",
    "    print(score_dict)\n",
    "    print(SD_dict)\n",
    "    #names[dfnameslist.index(combination[0])]+' vs '+ names[dfnameslist.index(combination[1])]\n",
    "\n",
    "mean_instruction_types(hapticDF, NonhapticDF)\n",
    "mean_instruction_types(hapticDF2, NonhapticDF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.138257575757575"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((4.234848484848484 + 4.212121212121212) + (4.113636363636363 + 3.992424242424242))/ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_cronbach_alpha_PI_questions(Touch_1, Touch_2):\n",
    "    touch_1df = df[Touch_1][2:]\n",
    "    touch_2df = df[Touch_2][2:]\n",
    "    \n",
    "    touch_1_list = []\n",
    "    for column in touch_1df.columns:\n",
    "        touch_1_list.append([elem for elem in touch_1df[column].tolist() if type(elem) != float])\n",
    "\n",
    "    touch_1_list_int = [int(a) for b in touch_1_list for a in b]\n",
    "\n",
    "    touch_2_list = []\n",
    "    for column in touch_2df.columns:\n",
    "        touch_2_list.append([elem for elem in touch_2df[column].tolist() if type(elem) != float])\n",
    "\n",
    "    touch_2_list_int = [int(a) for b in touch_2_list for a in b]\n",
    "    \n",
    "    stackedDFtouch1 = touch_1df.stack(dropna=False).reset_index()\n",
    "    stackedDFtouch2 = touch_2df.stack(dropna=False).reset_index()\n",
    "    stackedDFtouch2 = stackedDFtouch2.rename(columns={0:'score'})\n",
    "    \n",
    "    result = pd.concat([stackedDFtouch1, stackedDFtouch2], axis=1)\n",
    "    result[0] = np.float32(result[0])\n",
    "    result['score'] = np.float32(result['score'])\n",
    "    \n",
    "    return pg.cronbach_alpha(data=result[[0, 'score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_purchase_intention(df1, df2):\n",
    "    names =['haptic', 'nonhaptic']\n",
    "    dflist = [df1, df2]\n",
    "\n",
    "    comparisondict = {'df1':dict(), 'df2':dict()}\n",
    "    for dfname, df in list(zip(comparisondict.keys(), dflist)):\n",
    "        for column in df.columns:\n",
    "            comparisondict[dfname][column] = [int(a) for b in [elem for elem in df[column].tolist() if type(elem) != float] for a in b]\n",
    "    \n",
    "    for key in comparisondict.keys():\n",
    "        subdict = comparisondict[key]\n",
    "        comparisondict[key] = sum(subdict.values(), [])\n",
    "        \n",
    "    dfnameslist = list(comparisondict.keys())\n",
    "    \n",
    "    from itertools import combinations\n",
    "    for combination in list(combinations(comparisondict.keys(), 2)):\n",
    "        print(names[dfnameslist.index(combination[0])]+' vs '+ names[dfnameslist.index(combination[1])] + ' T-test')\n",
    "        print(stats.ttest_ind(comparisondict[combination[0]], comparisondict[combination[1]], equal_var=False))\n",
    "        \n",
    "from scipy.stats import f_oneway\n",
    "def TwoGroupAnova(df1, df2, names1, names2):\n",
    "    names =[names1, names2]\n",
    "    dflist = [df1, df2]\n",
    "\n",
    "    comparisondict = {'df1':dict(), 'df2':dict()}\n",
    "    for dfname, df in list(zip(comparisondict.keys(), dflist)):\n",
    "        for column in df.columns:\n",
    "            comparisondict[dfname][column] = [int(a) for b in [elem for elem in df[column].tolist() if type(elem) != float] for a in b]\n",
    "    \n",
    "    for key in comparisondict.keys():\n",
    "        subdict = comparisondict[key]\n",
    "        comparisondict[key] = sum(subdict.values(), [])\n",
    "\n",
    "    a = f_oneway(comparisondict['df1'], comparisondict['df2'])\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_onewayResult(statistic=0.012643313545112611, pvalue=0.910545341864542)\n"
     ]
    }
   ],
   "source": [
    "#t_test_purchase_intention(hapticDF, NonhapticDF)\n",
    "TwoGroupAnova(hapticDF, NonhapticDF, 'haptic', 'non-haptic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hypothesis 6\n",
    "H6: NFT moderates the relationship between haptic imagery and purchase intention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFT_score = ['Q114_1', 'Q114_2', 'Q114_3', 'Q114_4', 'Q114_5', 'Q114_6','NFT Instrumental_1', 'NFT Instrumental_2', 'NFT Instrumental_3', 'NFT Instrumental_4', 'NFT Instrumental_5', 'NFT Instrumental_6']\n",
    "\n",
    "for column in NFT_score:\n",
    "    df[column].loc[2:] = pd.to_numeric(df[column].loc[2:])\n",
    "\n",
    "df['NFT_score'] = df[NFT_score].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in df.index[1:]:\n",
    "    df['NFT_score'].loc[elem] = df['NFT_score'].loc[elem] / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0427350427350435"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([float(val) for val in df['NFT_score'].loc[1:]]) / len([float(val) for val in df['NFT_score'].loc[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9271276851734558, array([0.888, 0.957]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CronbachDF = df[NFT_score].loc[2:]\n",
    "\n",
    "for column in CronbachDF.columns:\n",
    "    CronbachDF[column] = pd.to_numeric(CronbachDF[column])\n",
    "    \n",
    "pg.cronbach_alpha(data=CronbachDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9334258018756403, array([0.895, 0.961])),\n",
       " (0.8771988710046533, array([0.806, 0.928])))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.cronbach_alpha(data=CronbachDF[['Q114_1','Q114_2','Q114_3','Q114_4','Q114_5','Q114_6']]), pg.cronbach_alpha(data=CronbachDF[['NFT Instrumental_1', 'NFT Instrumental_2', 'NFT Instrumental_3', 'NFT Instrumental_4', 'NFT Instrumental_5', 'NFT Instrumental_6']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "CronbachDF['Autotelic'] = CronbachDF[['Q114_1','Q114_2','Q114_3','Q114_4','Q114_5','Q114_6']].sum(axis=1)\n",
    "CronbachDF['Instrumental'] = CronbachDF[['NFT Instrumental_1', 'NFT Instrumental_2', 'NFT Instrumental_3', 'NFT Instrumental_4', 'NFT Instrumental_5', 'NFT Instrumental_6']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Autotelic</th>\n",
       "      <th>Instrumental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autotelic</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instrumental</th>\n",
       "      <td>0.616294</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Autotelic  Instrumental\n",
       "Autotelic      1.000000      0.616294\n",
       "Instrumental   0.616294      1.000000"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CronbachDF[['Autotelic', 'Instrumental']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLSdf_Nonhaptic = NonhapticDF\n",
    "OLSdf_Nonhaptic['Age'] = df['Q22'].loc[1:]\n",
    "OLSdf_Nonhaptic['Gender'] = df['Q113'].loc[1:]\n",
    "\n",
    "OLSdf_Nonhaptic['Haptic'] = 0\n",
    "\n",
    "OLSdf_Nonhaptic['NFT'] = df['NFT_score'].loc[1:]\n",
    "\n",
    "full_list = []\n",
    "\n",
    "for index in OLSdf_Nonhaptic.index:\n",
    "    for column in ['Q91','Q94','Q54','Q57','Q90','Q84','Q77','Q66']:\n",
    "        alist = [OLSdf_Nonhaptic[column].loc[index], OLSdf_Nonhaptic['Haptic'].loc[index] , OLSdf_Nonhaptic['NFT'].loc[index], OLSdf_haptic['Gender'].loc[index], OLSdf_haptic['Age'].loc[index]]\n",
    "        full_list.append(alist)\n",
    "        \n",
    "OLSdfNH = pd.DataFrame.from_records(full_list, columns=['PurchaseIntention', 'Haptic', 'NFT', 'Gender', 'Age'])\n",
    "\n",
    "OLSdfNH = OLSdfNH[OLSdfNH['PurchaseIntention'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLSdf_haptic = hapticDF\n",
    "OLSdf_haptic['Age'] = df['Q22'].loc[1:]\n",
    "OLSdf_haptic['Gender'] = df['Q113'].loc[1:]\n",
    "\n",
    "OLSdf_haptic['Haptic'] = 1\n",
    "\n",
    "OLSdf_haptic['NFT'] = df['NFT_score'].loc[1:]\n",
    "\n",
    "full_list = []\n",
    "\n",
    "for index in OLSdf_haptic.index:\n",
    "    for column in ['Q107','Q108','Q40','Q44','Q32','Q29','Q70','Q61']:\n",
    "        alist = [OLSdf_haptic[column].loc[index], OLSdf_haptic['Haptic'].loc[index] , OLSdf_haptic['NFT'].loc[index], OLSdf_haptic['Gender'].loc[index], OLSdf_haptic['Age'].loc[index]]\n",
    "        full_list.append(alist)\n",
    "        \n",
    "OLSdfHH = pd.DataFrame.from_records(full_list, columns=['PurchaseIntention', 'Haptic', 'NFT', 'Gender', 'Age'])\n",
    "\n",
    "OLSdfHH = OLSdfHH[OLSdfHH['PurchaseIntention'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([OLSdfHH, OLSdfNH])\n",
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in result.columns:\n",
    "    result[column] = pd.to_numeric(result[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.176282051282051"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['PurchaseIntention'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "#mod = smf.ols(\"Purchase Intention ~ C(Haptic):(NFT)\", data=result).fit()\n",
    "\n",
    "fit = ols('PurchaseIntention ~ C(Haptic)', data=result[['PurchaseIntention', 'Haptic']]).fit()\n",
    "fit2 = ols(\"PurchaseIntention ~ NFT\", data=result).fit()\n",
    "fit3 = ols(\"PurchaseIntention ~ C(Haptic):(NFT)\", data=result).fit()\n",
    "fit4 = ols(\"PurchaseIntention ~ C(Age) + C(Gender) + C(Haptic) + NFT + C(Haptic):(NFT)\", data=result).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>PurchaseIntention</td> <th>  R-squared:         </th> <td>   0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   3.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 30 Nov 2021</td>  <th>  Prob (F-statistic):</th>  <td>0.00270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:31:25</td>      <th>  Log-Likelihood:    </th> <td> -558.37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   312</td>       <th>  AIC:               </th> <td>   1135.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   303</td>       <th>  BIC:               </th> <td>   1168.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>    3.3689</td> <td>    0.447</td> <td>    7.533</td> <td> 0.000</td> <td>    2.489</td> <td>    4.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.3]</th>        <td>   -0.1696</td> <td>    0.233</td> <td>   -0.728</td> <td> 0.467</td> <td>   -0.628</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.5]</th>        <td>   -0.3977</td> <td>    0.318</td> <td>   -1.252</td> <td> 0.211</td> <td>   -1.022</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.6]</th>        <td>   -0.7016</td> <td>    0.287</td> <td>   -2.448</td> <td> 0.015</td> <td>   -1.266</td> <td>   -0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.7]</th>        <td>    0.3371</td> <td>    0.539</td> <td>    0.625</td> <td> 0.532</td> <td>   -0.724</td> <td>    1.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Gender)[T.2]</th>     <td>    0.3449</td> <td>    0.190</td> <td>    1.816</td> <td> 0.070</td> <td>   -0.029</td> <td>    0.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Haptic)[T.1]</th>     <td>   -0.0001</td> <td>    0.574</td> <td>   -0.000</td> <td> 1.000</td> <td>   -1.130</td> <td>    1.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NFT</th>                <td>    0.1934</td> <td>    0.105</td> <td>    1.839</td> <td> 0.067</td> <td>   -0.014</td> <td>    0.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Haptic)[T.1]:NFT</th> <td>    0.0048</td> <td>    0.136</td> <td>    0.035</td> <td> 0.972</td> <td>   -0.263</td> <td>    0.272</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>43.130</td> <th>  Durbin-Watson:     </th> <td>   1.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  16.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.334</td> <th>  Prob(JB):          </th> <td>0.000267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.094</td> <th>  Cond. No.          </th> <td>    41.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      PurchaseIntention   R-squared:                       0.074\n",
       "Model:                            OLS   Adj. R-squared:                  0.050\n",
       "Method:                 Least Squares   F-statistic:                     3.033\n",
       "Date:                Tue, 30 Nov 2021   Prob (F-statistic):            0.00270\n",
       "Time:                        11:31:25   Log-Likelihood:                -558.37\n",
       "No. Observations:                 312   AIC:                             1135.\n",
       "Df Residuals:                     303   BIC:                             1168.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept              3.3689      0.447      7.533      0.000       2.489       4.249\n",
       "C(Age)[T.3]           -0.1696      0.233     -0.728      0.467      -0.628       0.289\n",
       "C(Age)[T.5]           -0.3977      0.318     -1.252      0.211      -1.022       0.227\n",
       "C(Age)[T.6]           -0.7016      0.287     -2.448      0.015      -1.266      -0.138\n",
       "C(Age)[T.7]            0.3371      0.539      0.625      0.532      -0.724       1.398\n",
       "C(Gender)[T.2]         0.3449      0.190      1.816      0.070      -0.029       0.719\n",
       "C(Haptic)[T.1]        -0.0001      0.574     -0.000      1.000      -1.130       1.129\n",
       "NFT                    0.1934      0.105      1.839      0.067      -0.014       0.400\n",
       "C(Haptic)[T.1]:NFT     0.0048      0.136      0.035      0.972      -0.263       0.272\n",
       "==============================================================================\n",
       "Omnibus:                       43.130   Durbin-Watson:                   1.616\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               16.460\n",
       "Skew:                          -0.334   Prob(JB):                     0.000267\n",
       "Kurtosis:                       2.094   Cond. No.                         41.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale= StandardScaler()\n",
    "\n",
    "scaled_data = scale.fit_transform(pd.DataFrame(result['NFT'])) \n",
    "\n",
    "result['NFT'] = pd.DataFrame(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "#mod = smf.ols(\"Purchase Intention ~ C(Haptic):(NFT)\", data=result).fit()\n",
    "\n",
    "fit = ols('PurchaseIntention ~ C(Haptic)', data=result[['PurchaseIntention', 'Haptic']]).fit()\n",
    "fit2 = ols(\"PurchaseIntention ~ NFT\", data=result).fit()\n",
    "fit3 = ols(\"PurchaseIntention ~ C(Haptic):(NFT)\", data=result).fit()\n",
    "fit4 = ols(\"PurchaseIntention ~ C(Age) + C(Gender) + C(Haptic) + NFT + C(Haptic):(NFT)\", data=result).fit()\n",
    "#fit5 = ols(\"PurchaseIntention ~ C(Age) + C(Gender) + C(Haptic):(NFT)\", data=result).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>PurchaseIntention</td> <th>  R-squared:         </th> <td>   0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   3.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 29 Nov 2021</td>  <th>  Prob (F-statistic):</th>  <td>0.00270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:03:02</td>      <th>  Log-Likelihood:    </th> <td> -558.37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   312</td>       <th>  AIC:               </th> <td>   1135.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   303</td>       <th>  BIC:               </th> <td>   1168.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>    4.1509</td> <td>    0.162</td> <td>   25.646</td> <td> 0.000</td> <td>    3.832</td> <td>    4.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.3]</th>        <td>   -0.1696</td> <td>    0.233</td> <td>   -0.728</td> <td> 0.467</td> <td>   -0.628</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.5]</th>        <td>   -0.3977</td> <td>    0.318</td> <td>   -1.252</td> <td> 0.211</td> <td>   -1.022</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.6]</th>        <td>   -0.7016</td> <td>    0.287</td> <td>   -2.448</td> <td> 0.015</td> <td>   -1.266</td> <td>   -0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.7]</th>        <td>    0.3371</td> <td>    0.539</td> <td>    0.625</td> <td> 0.532</td> <td>   -0.724</td> <td>    1.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Gender)[T.2]</th>     <td>    0.3449</td> <td>    0.190</td> <td>    1.816</td> <td> 0.070</td> <td>   -0.029</td> <td>    0.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Haptic)[T.1]</th>     <td>    0.0192</td> <td>    0.166</td> <td>    0.116</td> <td> 0.908</td> <td>   -0.308</td> <td>    0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NFT</th>                <td>    0.2369</td> <td>    0.129</td> <td>    1.839</td> <td> 0.067</td> <td>   -0.017</td> <td>    0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Haptic)[T.1]:NFT</th> <td>    0.0059</td> <td>    0.166</td> <td>    0.035</td> <td> 0.972</td> <td>   -0.322</td> <td>    0.333</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>43.130</td> <th>  Durbin-Watson:     </th> <td>   1.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  16.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.334</td> <th>  Prob(JB):          </th> <td>0.000267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.094</td> <th>  Cond. No.          </th> <td>    8.24</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      PurchaseIntention   R-squared:                       0.074\n",
       "Model:                            OLS   Adj. R-squared:                  0.050\n",
       "Method:                 Least Squares   F-statistic:                     3.033\n",
       "Date:                Mon, 29 Nov 2021   Prob (F-statistic):            0.00270\n",
       "Time:                        23:03:02   Log-Likelihood:                -558.37\n",
       "No. Observations:                 312   AIC:                             1135.\n",
       "Df Residuals:                     303   BIC:                             1168.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept              4.1509      0.162     25.646      0.000       3.832       4.469\n",
       "C(Age)[T.3]           -0.1696      0.233     -0.728      0.467      -0.628       0.289\n",
       "C(Age)[T.5]           -0.3977      0.318     -1.252      0.211      -1.022       0.227\n",
       "C(Age)[T.6]           -0.7016      0.287     -2.448      0.015      -1.266      -0.138\n",
       "C(Age)[T.7]            0.3371      0.539      0.625      0.532      -0.724       1.398\n",
       "C(Gender)[T.2]         0.3449      0.190      1.816      0.070      -0.029       0.719\n",
       "C(Haptic)[T.1]         0.0192      0.166      0.116      0.908      -0.308       0.347\n",
       "NFT                    0.2369      0.129      1.839      0.067      -0.017       0.491\n",
       "C(Haptic)[T.1]:NFT     0.0059      0.166      0.035      0.972      -0.322       0.333\n",
       "==============================================================================\n",
       "Omnibus:                       43.130   Durbin-Watson:                   1.616\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               16.460\n",
       "Skew:                          -0.334   Prob(JB):                     0.000267\n",
       "Kurtosis:                       2.094   Cond. No.                         8.24\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hypothesis 7\n",
    "Participants are unable to distinguish GPT-3-generated product descriptions from human-written product descriptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the AI product descriptions, participants guessed it was AI written 82 times, and Human written 74 times\n",
      "In the Human product descriptions, participants guessed it was AI written 87 times, and Human written 69 times\n"
     ]
    }
   ],
   "source": [
    "#optie 1 is written by human, optie 2 is generated by AI\n",
    "df[AIproducts].loc[2:]\n",
    "\n",
    "print('In the AI product descriptions, participants guessed it was AI written {} times, and Human written {} times'.format((df[AIproducts].values == '2').sum(), (df[AIproducts].values == '1').sum()))\n",
    "\n",
    "print('In the Human product descriptions, participants guessed it was AI written {} times, and Human written {} times'.format((df[Humanproducts].values == '2').sum(), (df[Humanproducts].values == '1').sum()))\n",
    "#df[Humanproducts].loc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1calculate the percentage of correct origins guesses per participant\n",
    "#check\n",
    "#1calculate the average percentage of correct origins guesses for all participants and the 95 confidence interval\n",
    "#check\n",
    "#Perform a Wilcoxon signed-rank test\n",
    "#check\n",
    "#Perform A Bayesian binomial test yields \n",
    "#check\n",
    "#Perform a mixed-effects probit regressions on detection accuracy for each round.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the percentage of correct origins guesses per participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIcolumns = ['Q64','Q88','Q82','Q86','Q99','Q110','Q102','Q109']\n",
    "HumanColumns = ['Q36','Q55','Q46','Q59','Q72','Q80','Q81','Q68']\n",
    "AIdfGuess = df[AIproducts+Humanproducts].loc[2:]\n",
    "AIdfGuess['CorrectRateAI'] = np.nan\n",
    "AIdfGuess['CorrectRateHuman'] = np.nan\n",
    "\n",
    "for index in AIdfGuess.index:\n",
    "    correctAI = 0\n",
    "    for column in AIcolumns:\n",
    "        if AIdfGuess[column].loc[index] == '2':\n",
    "            correctAI +=1\n",
    "    \n",
    "    AIdfGuess['CorrectRateAI'].loc[index] = correctAI /4\n",
    "    \n",
    "    correctHuman = 0\n",
    "    for column in HumanColumns:\n",
    "        if AIdfGuess[column].loc[index] == '1':\n",
    "            correctHuman +=1\n",
    "    \n",
    "    AIdfGuess['CorrectRateHuman'].loc[index] = correctHuman /4\n",
    "\n",
    "AIdfGuess['CorrectTotal'] = AIdfGuess[['CorrectRateAI','CorrectRateHuman']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the average percentage of correct origins guesses for all participants and the 95 confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return round(m-h, 4), round(m+h, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.483974358974359 (0.4338, 0.5342)\n"
     ]
    }
   ],
   "source": [
    "print(AIdfGuess['CorrectTotal'].mean(), mean_confidence_interval(AIdfGuess['CorrectTotal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilcoxon signed rank test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.5 0.5077668526486252\n"
     ]
    }
   ],
   "source": [
    "AIdfGuess['Chance'] = 0.5\n",
    "AIdfGuess['Diff'] = AIdfGuess['CorrectTotal'] - AIdfGuess['Chance']\n",
    "from scipy.stats import wilcoxon\n",
    "w, p = wilcoxon(AIdfGuess['Diff'])\n",
    "#w, p = wilcoxon(AIdfGuess['Diff'], alternative='less')\n",
    "print(w, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([6, 8, 14, 16, 23, 24, 28, 29, 41, -48, 49, 56, 60, -67, 75])\n",
    "sum(6, 8, 14, 16, 23, 24, 28, 29, )\n",
    "#whereas it is 24 in the two-sided case (the minimum of sum of ranks above and below zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes factor of a binomial test with ùëò successes, ùëõ trials and base probability ùëù."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF-null: 12.041, BF-alt: 0.083\n"
     ]
    }
   ],
   "source": [
    "correctAI = 0\n",
    "correctHuman = 0\n",
    "for index in AIdfGuess.index:\n",
    "    \n",
    "    for column in AIcolumns:\n",
    "        if AIdfGuess[column].loc[index] == '2':\n",
    "            correctAI +=1\n",
    "    \n",
    "\n",
    "    for column in HumanColumns:\n",
    "        if AIdfGuess[column].loc[index] == '1':\n",
    "            correctHuman +=1\n",
    "            \n",
    "totalcorrect = correctAI + correctHuman\n",
    "\n",
    "totalguesses = sum(AIdfGuess[AIcolumns + HumanColumns].notna().sum().tolist())\n",
    "\n",
    "import pingouin as pg\n",
    "bf = float(pg.bayesfactor_binom(k=totalcorrect, n=totalguesses, p=0.5))\n",
    "# Note that Pingouin returns the BF-alt by default.\n",
    "# BF-null is simply 1 / BF-alt\n",
    "print(\"BF-null: %.3f, BF-alt: %.3f\" % (1 / bf, bf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 312\n"
     ]
    }
   ],
   "source": [
    "print(totalcorrect, totalguesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Bayes Factor of the null hypothesis (‚Äúthe coin is fair‚Äù) is higher than the Bayes Factor of the alternative hypothesis (‚Äúthe coin is not fair‚Äù), we can conclude that there is more evidence to support the fact that the coin is indeed fair. However, the strength of the evidence in favor of the null hypothesis (1.197) is ‚Äúbarely worth mentionning‚Äù according to Jeffreys‚Äôs rule of thumb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a mixed-effects probit regressions on detection accuracy for each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-72f977481693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAIdfGuess\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Q22'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "AIdfGuess['Age'] = df['Q22'].loc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIdfGuess['Gender'] = df['Q113'].loc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "#mod = smf.ols(\"Purchase Intention ~ C(Haptic):(NFT)\", data=result).fit()\n",
    "\n",
    "fit = ols('CorrectTotal ~ C(Gender) + C(Age)', data=AIdfGuess[['CorrectTotal', 'Gender', 'Age']]).fit()\n",
    "#fit2 = ols(\"PurchaseIntention ~ C(Haptic):(NFT)\", data=result).fit()\n",
    "fit2 = ols('CorrectTotal ~ C(Age)', data=AIdfGuess[['CorrectTotal', 'Age']]).fit()\n",
    "fit3 = ols('CorrectTotal ~ C(Gender)', data=AIdfGuess[['CorrectTotal', 'Gender']]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>CorrectTotal</td>   <th>  R-squared:         </th> <td>   0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.3125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 29 Nov 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.902</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:36:55</td>     <th>  Log-Likelihood:    </th> <td>  18.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    39</td>      <th>  AIC:               </th> <td>  -25.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    33</td>      <th>  BIC:               </th> <td>  -15.62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    0.4467</td> <td>    0.043</td> <td>   10.328</td> <td> 0.000</td> <td>    0.359</td> <td>    0.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Gender)[T.2]</th> <td>    0.0661</td> <td>    0.056</td> <td>    1.176</td> <td> 0.248</td> <td>   -0.048</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.3]</th>    <td>    0.0439</td> <td>    0.073</td> <td>    0.605</td> <td> 0.549</td> <td>   -0.104</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.5]</th>    <td>   -0.0109</td> <td>    0.088</td> <td>   -0.124</td> <td> 0.902</td> <td>   -0.190</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.6]</th>    <td>    0.0038</td> <td>    0.089</td> <td>    0.042</td> <td> 0.967</td> <td>   -0.178</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.7]</th>    <td>    0.0533</td> <td>    0.168</td> <td>    0.317</td> <td> 0.753</td> <td>   -0.289</td> <td>    0.395</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.161</td> <th>  Durbin-Watson:     </th> <td>   2.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.560</td> <th>  Jarque-Bera (JB):  </th> <td>   1.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.378</td> <th>  Prob(JB):          </th> <td>   0.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.690</td> <th>  Cond. No.          </th> <td>    7.40</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           CorrectTotal   R-squared:                       0.045\n",
       "Model:                            OLS   Adj. R-squared:                 -0.099\n",
       "Method:                 Least Squares   F-statistic:                    0.3125\n",
       "Date:                Mon, 29 Nov 2021   Prob (F-statistic):              0.902\n",
       "Time:                        21:36:55   Log-Likelihood:                 18.802\n",
       "No. Observations:                  39   AIC:                            -25.60\n",
       "Df Residuals:                      33   BIC:                            -15.62\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          0.4467      0.043     10.328      0.000       0.359       0.535\n",
       "C(Gender)[T.2]     0.0661      0.056      1.176      0.248      -0.048       0.180\n",
       "C(Age)[T.3]        0.0439      0.073      0.605      0.549      -0.104       0.192\n",
       "C(Age)[T.5]       -0.0109      0.088     -0.124      0.902      -0.190       0.168\n",
       "C(Age)[T.6]        0.0038      0.089      0.042      0.967      -0.178       0.185\n",
       "C(Age)[T.7]        0.0533      0.168      0.317      0.753      -0.289       0.395\n",
       "==============================================================================\n",
       "Omnibus:                        1.161   Durbin-Watson:                   2.060\n",
       "Prob(Omnibus):                  0.560   Jarque-Bera (JB):                1.085\n",
       "Skew:                          -0.378   Prob(JB):                        0.581\n",
       "Kurtosis:                       2.690   Cond. No.                         7.40\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H8: Participants express at least the same intention to purchase when viewing an apparel product which text is generated by AI compared to human-written text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ttest between low haptic human and low haptic AI\n",
    "LowNFTAI = [LowNFTWomenAI, LowNFTMenAI]\n",
    "LowNFTHuman = [LowNFTWomenHuman, LowNFTMenHuman]\n",
    "\n",
    "HighNFTAI = [HighNFTWomenAI, HighNFTMenAI]\n",
    "HighNFTHuman = [HighNFTWomenHuman, HighNFTMenHuman]\n",
    "\n",
    "Q1_LowNFTAI = [elem[0] for sublist  in LowNFTAI for elem in sublist]\n",
    "Q2_LowNFTAI = [elem[1] for sublist  in LowNFTAI for elem in sublist]\n",
    "Q1_LowNFTHuman = [elem[0] for sublist  in LowNFTHuman for elem in sublist]\n",
    "Q2_LowNFTHuman = [elem[1] for sublist  in LowNFTHuman for elem in sublist]\n",
    "Q1_HighNFTAI = [elem[0] for sublist  in HighNFTAI for elem in sublist]\n",
    "Q2_HighNFTAI = [elem[1] for sublist  in HighNFTAI for elem in sublist]\n",
    "Q1_HighNFTHuman = [elem[0] for sublist  in HighNFTHuman for elem in sublist]\n",
    "Q2_HighNFTHuman = [elem[1] for sublist  in HighNFTHuman for elem in sublist]\n",
    "\n",
    "#Ttest between high haptic human and high haptic AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'haptic': 4.230769230769231, 'non-haptic': 4.102564102564102}\n",
      "{'haptic': 1.4587227727954781, 'non-haptic': 1.4996947186291778}\n"
     ]
    }
   ],
   "source": [
    "mean_instruction_types(df[Q1_LowNFTAI].loc[1:], df[Q1_LowNFTHuman].loc[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'haptic': 4.166666666666667, 'non-haptic': 4.205128205128205}\n",
      "{'haptic': 1.4895015000377538, 'non-haptic': 1.6064720914950812}\n"
     ]
    }
   ],
   "source": [
    "mean_instruction_types(df[Q1_HighNFTAI].loc[1:], df[Q1_HighNFTHuman].loc[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haptic vs nonhaptic T-test\n",
      "Ttest_indResult(statistic=0.5412109683235555, pvalue=0.5891448257672807)\n"
     ]
    }
   ],
   "source": [
    "t_test_purchase_intention(df[Q1_LowNFTAI].loc[1:], df[Q1_LowNFTHuman].loc[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haptic vs nonhaptic T-test\n",
      "Ttest_indResult(statistic=-0.15505363758730226, pvalue=0.8769832247225391)\n"
     ]
    }
   ],
   "source": [
    "t_test_purchase_intention(df[Q1_HighNFTAI].loc[1:], df[Q1_HighNFTHuman].loc[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haptic vs nonhaptic T-test\n",
      "Ttest_indResult(statistic=1.233090487559421, pvalue=0.2194230447690444)\n"
     ]
    }
   ],
   "source": [
    "t_test_purchase_intention(df[Q2_LowNFTAI].loc[1:], df[Q2_LowNFTHuman].loc[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haptic vs nonhaptic T-test\n",
      "Ttest_indResult(statistic=-0.8848600883100278, pvalue=0.3776127355058849)\n"
     ]
    }
   ],
   "source": [
    "t_test_purchase_intention(df[Q2_HighNFTAI].loc[1:], df[Q2_HighNFTHuman].loc[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "def TwoGroupAnova(df1, df2, names1, names2):\n",
    "    names =[names1, names2]\n",
    "    dflist = [df1, df2]\n",
    "\n",
    "    comparisondict = {'df1':dict(), 'df2':dict()}\n",
    "    for dfname, df in list(zip(comparisondict.keys(), dflist)):\n",
    "        for column in df.columns:\n",
    "            comparisondict[dfname][column] = [int(a) for b in [elem for elem in df[column].tolist() if type(elem) != float] for a in b]\n",
    "    \n",
    "    for key in comparisondict.keys():\n",
    "        subdict = comparisondict[key]\n",
    "        comparisondict[key] = sum(subdict.values(), [])\n",
    "\n",
    "    a = f_oneway(comparisondict['df1'], comparisondict['df2'])\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_onewayResult(statistic=1.520512150509538, pvalue=0.21942093247135033)\n",
      "F_onewayResult(statistic=1.520512150509538, pvalue=0.21942093247135033)\n",
      "F_onewayResult(statistic=0.02404163052905464, pvalue=0.8769820697008214)\n",
      "F_onewayResult(statistic=0.2929093122337188, pvalue=0.5891442266356117)\n"
     ]
    }
   ],
   "source": [
    "TwoGroupAnova(df[Q2_LowNFTAI].loc[2:], df[Q2_LowNFTHuman].loc[2:], 'AI', 'Human')\n",
    "TwoGroupAnova(df[Q2_LowNFTAI].loc[2:], df[Q2_LowNFTHuman].loc[2:], 'AI', 'Human')\n",
    "TwoGroupAnova(df[Q1_HighNFTAI].loc[2:], df[Q1_HighNFTHuman].loc[2:], 'AI', 'Human')\n",
    "TwoGroupAnova(df[Q1_LowNFTAI].loc[2:], df[Q1_LowNFTHuman].loc[2:], 'AI', 'Human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram van de purchase intent humans vs AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the perception whether someone thinks it is AI influence the purchase intention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLSdf_Nonhaptic = NonhapticDF\n",
    "\n",
    "OLSdf_Nonhaptic['Haptic'] = 0\n",
    "\n",
    "OLSdf_Nonhaptic['NFT'] = df['NFT_score'].loc[2:]\n",
    "\n",
    "full_list = []\n",
    "\n",
    "for index in OLSdf_Nonhaptic.index:\n",
    "    for column in ['Q91','Q94','Q54','Q57','Q90','Q84','Q77','Q66']:\n",
    "        alist = [OLSdf_Nonhaptic[column].loc[index], OLSdf_Nonhaptic['Haptic'].loc[index] , OLSdf_Nonhaptic['NFT'].loc[index]]\n",
    "        full_list.append(alist)\n",
    "        \n",
    "OLSdfNH = pd.DataFrame.from_records(full_list, columns=['PurchaseIntention', 'Haptic', 'NFT'])\n",
    "\n",
    "OLSdfNH = OLSdfNH[OLSdfNH['PurchaseIntention'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "GuessQuestions = AIproducts + Humanproducts\n",
    "Q1List = ['Q32', 'Q90', 'Q29', 'Q84', 'Q107', 'Q91', 'Q108', 'Q94', 'Q40', 'Q54', 'Q44', 'Q57', 'Q70', 'Q77', 'Q61', 'Q66']\n",
    "Q2List = ['Q33', 'Q89', 'Q30', 'Q85', 'Q100', 'Q92', 'Q98', 'Q95', 'Q41', 'Q53', 'Q45', 'Q58', 'Q71', 'Q78', 'Q63', 'Q67']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1GuessesList = list(zip(GuessQuestions, Q1List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[[Q1GuessesList[0][0], Q1GuessesList[0][1]]].loc[2:]\n",
    "fulllist = []\n",
    "for pair in Q1GuessesList:\n",
    "    subdf = df[[pair[0], pair[1]]].loc[2:]\n",
    "    for index in subdf.index:\n",
    "        if type(subdf[pair[0]].loc[index]) == str:\n",
    "            fulllist.append([subdf[pair[0]].loc[index], subdf[pair[1]].loc[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "GuessDF = pd.DataFrame.from_records(fulllist, columns=['Guess', 'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in GuessDF.columns:\n",
    "    GuessDF[column] = pd.to_numeric(GuessDF[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 = ols('PI ~ C(Guess)', data=GuessDF[['Guess', 'PI']]).fit()\n",
    "fit4 = ols('Guess ~ PI', data=GuessDF[['Guess', 'PI']]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>PI</td>        <th>  R-squared:         </th> <td>   0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   18.67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 29 Nov 2021</td> <th>  Prob (F-statistic):</th> <td>2.09e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:37:44</td>     <th>  Log-Likelihood:    </th> <td> -561.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   312</td>      <th>  AIC:               </th> <td>   1127.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   310</td>      <th>  BIC:               </th> <td>   1134.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>    4.5664</td> <td>    0.123</td> <td>   37.224</td> <td> 0.000</td> <td>    4.325</td> <td>    4.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Guess)[T.2]</th> <td>   -0.7203</td> <td>    0.167</td> <td>   -4.321</td> <td> 0.000</td> <td>   -1.048</td> <td>   -0.392</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>104.451</td> <th>  Durbin-Watson:     </th> <td>   2.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  20.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.305</td>  <th>  Prob(JB):          </th> <td>3.08e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.893</td>  <th>  Cond. No.          </th> <td>    2.73</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     PI   R-squared:                       0.057\n",
       "Model:                            OLS   Adj. R-squared:                  0.054\n",
       "Method:                 Least Squares   F-statistic:                     18.67\n",
       "Date:                Mon, 29 Nov 2021   Prob (F-statistic):           2.09e-05\n",
       "Time:                        21:37:44   Log-Likelihood:                -561.26\n",
       "No. Observations:                 312   AIC:                             1127.\n",
       "Df Residuals:                     310   BIC:                             1134.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept         4.5664      0.123     37.224      0.000       4.325       4.808\n",
       "C(Guess)[T.2]    -0.7203      0.167     -4.321      0.000      -1.048      -0.392\n",
       "==============================================================================\n",
       "Omnibus:                      104.451   Durbin-Watson:                   2.146\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               20.775\n",
       "Skew:                          -0.305   Prob(JB):                     3.08e-05\n",
       "Kurtosis:                       1.893   Cond. No.                         2.73\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optie 1 is written by human, optie 2 is generated by AI\n",
    "#So if participants think a product description is generated by AI, their purchase intention is .66 lower. \n",
    "#However, reversed causality is likely, since participants first indicate their purchase intention and then whether they think whether it was generated by AI\n",
    "fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does the moderation effect differ between jeans and hoodies?\n",
    "\n",
    "#woman\n",
    "HighNFTHuman_hoodieWomen = ['Q70', 'Q71']\n",
    "\n",
    "LowNFTHuman_hoodieWomen = ['Q77', 'Q78']\n",
    "\n",
    "HighNFTAI_hoodieWomen = ['Q32', 'Q33']\n",
    "\n",
    "LowNFTAI_hoodieWomen = ['Q90', 'Q89']\n",
    "\n",
    "    #Jeans\n",
    "\n",
    "HighNFTHuman_jeansWomen = ['Q61', 'Q63']\n",
    "\n",
    "LowNFTHuman_jeansWomen = ['Q66', 'Q67']\n",
    "\n",
    "HighNFTAI_jeansWomen = ['Q29', 'Q30']\n",
    "\n",
    "LowNFTAI_jeansWomen = ['Q84', 'Q85']\n",
    "\n",
    "HighNFTWomenAIHoodie = [HighNFTAI_hoodieWomen]\n",
    "LowNFTWomenAIHoodie = [LowNFTAI_hoodieWomen]\n",
    "HighNFTWomenHumanHoodie = [HighNFTHuman_hoodieWomen]\n",
    "LowNFTWomenHumanHoodie = [LowNFTHuman_hoodieWomen]\n",
    "\n",
    "HighNFTWomenHoodie = [HighNFTWomenAI, HighNFTWomenHuman]\n",
    "LowNFTWomenHoodie = [LowNFTWomenAI, LowNFTWomenHuman]\n",
    "\n",
    "\n",
    "#men\n",
    "HighNFTHuman_hoodieMen = ['Q40', 'Q41']\n",
    "\n",
    "LowNFTHuman_hoodieMen = ['Q54', 'Q53']\n",
    "\n",
    "HighNFTAI_hoodieMen = ['Q107', 'Q100']\n",
    "\n",
    "LowNFTAI_hoodieMen = ['Q91', 'Q92']\n",
    "\n",
    "    #Jeans\n",
    "\n",
    "HighNFTHuman_jeansMen = ['Q44', 'Q45']\n",
    "\n",
    "LowNFTHuman_jeansMen = ['Q57', 'Q58']\n",
    "\n",
    "HighNFTAI_jeansMen = ['Q108', 'Q98']\n",
    "\n",
    "LowNFTAI_jeansMen = ['Q94', 'Q95']\n",
    "\n",
    "HighNFTMenAIHoodie = [HighNFTAI_hoodieMen]\n",
    "LowNFTMenAIHoodie = [LowNFTAI_hoodieMen]\n",
    "HighNFTMenHumanHoodie = [HighNFTHuman_hoodieMen]\n",
    "LowNFTMenHumanHoodie = [LowNFTHuman_hoodieMen]\n",
    "\n",
    "HighNFTMenHoodie = [HighNFTMenAI, HighNFTMenHuman]\n",
    "LowNFTMenHoodie = [LowNFTMenAI, LowNFTMenHuman]\n",
    "\n",
    "HighNFTHoodie = [HighNFTMenHoodie, HighNFTWomenHoodie]\n",
    "LowNFTHoodie = [LowNFTMenHoodie, LowNFTWomenHoodie]\n",
    "\n",
    "\n",
    "Q1_HighNFTHoodie = [elem[0] for subsublist  in [item for sublist in HighNFTHoodie for item in sublist] for elem in subsublist]\n",
    "Q2_HighNFTHoodie = [elem[1] for subsublist  in [item for sublist in HighNFTHoodie for item in sublist] for elem in subsublist]\n",
    "Q1_LowNFTHoodie = [elem[0] for subsublist  in [item for sublist in LowNFTHoodie for item in sublist] for elem in subsublist]\n",
    "Q2_LowNFTHoodie = [elem[1] for subsublist  in [item for sublist in LowNFTHoodie for item in sublist] for elem in subsublist]\n",
    "\n",
    "#Jeans part\n",
    "\n",
    "HighNFTWomenAIJeans = [HighNFTAI_jeansWomen]\n",
    "LowNFTWomenAIJeans = [LowNFTAI_jeansWomen]\n",
    "HighNFTWomenHumanJeans = [HighNFTHuman_jeansWomen]\n",
    "LowNFTWomenHumanJeans = [LowNFTHuman_jeansWomen]\n",
    "\n",
    "HighNFTWomenJeans = [HighNFTWomenAIJeans, HighNFTWomenHumanJeans]\n",
    "LowNFTWomenJeans = [LowNFTWomenAIJeans, LowNFTWomenHumanJeans]\n",
    "\n",
    "HighNFTWomen = [HighNFTWomenAIJeans, HighNFTWomenHumanJeans]\n",
    "LowNFTWomen = [LowNFTWomenAIJeans, LowNFTWomenHumanJeans]\n",
    "\n",
    "#####\n",
    "\n",
    "HighNFTMenAIJeans = [HighNFTAI_jeansMen]\n",
    "LowNFTMenAIJeans = [LowNFTAI_jeansMen]\n",
    "HighNFTMenHumanJeans = [HighNFTHuman_jeansMen]\n",
    "LowNFTMenHumanJeans = [LowNFTHuman_jeansMen]\n",
    "\n",
    "HighNFTMenJeans = [HighNFTMenAIJeans, HighNFTMenHumanJeans]\n",
    "LowNFTMenJeans = [LowNFTMenAIJeans, LowNFTMenHumanJeans]\n",
    "\n",
    "HighNFTJeans = [HighNFTMenJeans, HighNFTWomenJeans]\n",
    "LowNFTJeans = [LowNFTMenJeans, LowNFTWomenJeans]\n",
    "\n",
    "Q1_HighNFTJeans = [elem[0] for subsublist  in [item for sublist in HighNFTJeans for item in sublist] for elem in subsublist]\n",
    "Q2_HighNFTJeans = [elem[1] for subsublist  in [item for sublist in HighNFTJeans for item in sublist] for elem in subsublist]\n",
    "Q1_LowNFTJeans = [elem[0] for subsublist  in [item for sublist in LowNFTJeans for item in sublist] for elem in subsublist]\n",
    "Q2_LowNFTJeans = [elem[1] for subsublist  in [item for sublist in LowNFTJeans for item in sublist] for elem in subsublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>PurchaseIntention</td> <th>  R-squared:         </th> <td>   0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   2.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 30 Nov 2021</td>  <th>  Prob (F-statistic):</th>  <td>0.0246</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:45:15</td>      <th>  Log-Likelihood:    </th> <td> -278.71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   156</td>       <th>  AIC:               </th> <td>   575.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   147</td>       <th>  BIC:               </th> <td>   602.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>    3.1672</td> <td>    0.640</td> <td>    4.948</td> <td> 0.000</td> <td>    1.902</td> <td>    4.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.3]</th>        <td>   -0.2494</td> <td>    0.333</td> <td>   -0.748</td> <td> 0.456</td> <td>   -0.908</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.5]</th>        <td>   -0.4729</td> <td>    0.454</td> <td>   -1.041</td> <td> 0.300</td> <td>   -1.371</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.6]</th>        <td>   -0.6650</td> <td>    0.410</td> <td>   -1.621</td> <td> 0.107</td> <td>   -1.476</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.7]</th>        <td>   -0.2365</td> <td>    0.772</td> <td>   -0.306</td> <td> 0.760</td> <td>   -1.762</td> <td>    1.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Gender)[T.2]</th>     <td>    0.2700</td> <td>    0.272</td> <td>    0.994</td> <td> 0.322</td> <td>   -0.267</td> <td>    0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Haptic)[T.1]</th>     <td>   -0.3122</td> <td>    0.822</td> <td>   -0.380</td> <td> 0.704</td> <td>   -1.936</td> <td>    1.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NFT</th>                <td>    0.2722</td> <td>    0.151</td> <td>    1.808</td> <td> 0.073</td> <td>   -0.025</td> <td>    0.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Haptic)[T.1]:NFT</th> <td>    0.0265</td> <td>    0.194</td> <td>    0.136</td> <td> 0.892</td> <td>   -0.358</td> <td>    0.411</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>31.711</td> <th>  Durbin-Watson:     </th> <td>   1.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>   8.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.228</td> <th>  Prob(JB):          </th> <td>  0.0148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.957</td> <th>  Cond. No.          </th> <td>    41.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      PurchaseIntention   R-squared:                       0.111\n",
       "Model:                            OLS   Adj. R-squared:                  0.062\n",
       "Method:                 Least Squares   F-statistic:                     2.285\n",
       "Date:                Tue, 30 Nov 2021   Prob (F-statistic):             0.0246\n",
       "Time:                        14:45:15   Log-Likelihood:                -278.71\n",
       "No. Observations:                 156   AIC:                             575.4\n",
       "Df Residuals:                     147   BIC:                             602.9\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept              3.1672      0.640      4.948      0.000       1.902       4.432\n",
       "C(Age)[T.3]           -0.2494      0.333     -0.748      0.456      -0.908       0.409\n",
       "C(Age)[T.5]           -0.4729      0.454     -1.041      0.300      -1.371       0.425\n",
       "C(Age)[T.6]           -0.6650      0.410     -1.621      0.107      -1.476       0.146\n",
       "C(Age)[T.7]           -0.2365      0.772     -0.306      0.760      -1.762       1.289\n",
       "C(Gender)[T.2]         0.2700      0.272      0.994      0.322      -0.267       0.807\n",
       "C(Haptic)[T.1]        -0.3122      0.822     -0.380      0.704      -1.936       1.311\n",
       "NFT                    0.2722      0.151      1.808      0.073      -0.025       0.570\n",
       "C(Haptic)[T.1]:NFT     0.0265      0.194      0.136      0.892      -0.358       0.411\n",
       "==============================================================================\n",
       "Omnibus:                       31.711   Durbin-Watson:                   1.871\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                8.425\n",
       "Skew:                          -0.228   Prob(JB):                       0.0148\n",
       "Kurtosis:                       1.957   Cond. No.                         41.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapticDF = df[Q1_HighNFTJeans].loc[2:]\n",
    "NonhapticDF = df[Q1_LowNFTJeans].loc[2:]\n",
    "hapticDF2 = df[Q2_HighNFTJeans].loc[2:]\n",
    "NonhapticDF2 = df[Q2_LowNFTJeans].loc[2:]\n",
    "\n",
    "OLSdf_Nonhaptic = NonhapticDF\n",
    "OLSdf_Nonhaptic['Age'] = df['Q22'].loc[1:]\n",
    "OLSdf_Nonhaptic['Gender'] = df['Q113'].loc[1:]\n",
    "\n",
    "OLSdf_Nonhaptic['Haptic'] = 0\n",
    "\n",
    "OLSdf_Nonhaptic['NFT'] = df['NFT_score'].loc[1:]\n",
    "\n",
    "full_list = []\n",
    "\n",
    "for index in OLSdf_Nonhaptic.index:\n",
    "    for column in ['Q94','Q57','Q84','Q66']:\n",
    "        alist = [OLSdf_Nonhaptic[column].loc[index], OLSdf_Nonhaptic['Haptic'].loc[index] , OLSdf_Nonhaptic['NFT'].loc[index], OLSdf_haptic['Gender'].loc[index], OLSdf_haptic['Age'].loc[index]]\n",
    "        full_list.append(alist)\n",
    "\n",
    "OLSdfNH = pd.DataFrame.from_records(full_list, columns=['PurchaseIntention', 'Haptic', 'NFT', 'Gender', 'Age'])\n",
    "\n",
    "OLSdfNH = OLSdfNH[OLSdfNH['PurchaseIntention'].notna()]\n",
    "\n",
    "\n",
    "OLSdf_haptic = hapticDF\n",
    "OLSdf_haptic['Age'] = df['Q22'].loc[1:]\n",
    "OLSdf_haptic['Gender'] = df['Q113'].loc[1:]\n",
    "\n",
    "OLSdf_haptic['Haptic'] = 1\n",
    "\n",
    "OLSdf_haptic['NFT'] = df['NFT_score'].loc[1:]\n",
    "\n",
    "full_list = []\n",
    "\n",
    "for index in OLSdf_haptic.index:\n",
    "    for column in ['Q108','Q44','Q29','Q61']:\n",
    "        alist = [OLSdf_haptic[column].loc[index], OLSdf_haptic['Haptic'].loc[index] , OLSdf_haptic['NFT'].loc[index], OLSdf_haptic['Gender'].loc[index], OLSdf_haptic['Age'].loc[index]]\n",
    "        full_list.append(alist)\n",
    "\n",
    "OLSdfHH = pd.DataFrame.from_records(full_list, columns=['PurchaseIntention', 'Haptic', 'NFT', 'Gender', 'Age'])\n",
    "\n",
    "OLSdfHH = OLSdfHH[OLSdfHH['PurchaseIntention'].notna()]\n",
    "\n",
    "result = pd.concat([OLSdfHH, OLSdfNH])\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "for column in result.columns:\n",
    "    result[column] = pd.to_numeric(result[column])\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "#mod = smf.ols(\"Purchase Intention ~ C(Haptic):(NFT)\", data=result).fit()\n",
    "\n",
    "fit = ols('PurchaseIntention ~ C(Haptic)', data=result[['PurchaseIntention', 'Haptic']]).fit()\n",
    "fit2 = ols(\"PurchaseIntention ~ NFT\", data=result).fit()\n",
    "fit3 = ols(\"PurchaseIntention ~ C(Haptic):(NFT)\", data=result).fit()\n",
    "fit4 = ols(\"PurchaseIntention ~ C(Age) + C(Gender) + C(Haptic) + NFT + C(Haptic):(NFT)\", data=result).fit()\n",
    "\n",
    "fit4.summary()\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>PurchaseIntention</td> <th>  R-squared:         </th> <td>   0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   1.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 30 Nov 2021</td>  <th>  Prob (F-statistic):</th>  <td> 0.234</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:48:24</td>      <th>  Log-Likelihood:    </th> <td> -276.73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   156</td>       <th>  AIC:               </th> <td>   571.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   147</td>       <th>  BIC:               </th> <td>   598.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>    3.5707</td> <td>    0.632</td> <td>    5.649</td> <td> 0.000</td> <td>    2.322</td> <td>    4.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.3]</th>        <td>   -0.0898</td> <td>    0.329</td> <td>   -0.273</td> <td> 0.785</td> <td>   -0.740</td> <td>    0.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.5]</th>        <td>   -0.3224</td> <td>    0.449</td> <td>   -0.719</td> <td> 0.474</td> <td>   -1.209</td> <td>    0.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.6]</th>        <td>   -0.7381</td> <td>    0.405</td> <td>   -1.822</td> <td> 0.070</td> <td>   -1.539</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Age)[T.7]</th>        <td>    0.9107</td> <td>    0.762</td> <td>    1.195</td> <td> 0.234</td> <td>   -0.596</td> <td>    2.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Gender)[T.2]</th>     <td>    0.4197</td> <td>    0.268</td> <td>    1.564</td> <td> 0.120</td> <td>   -0.111</td> <td>    0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Haptic)[T.1]</th>     <td>    0.3119</td> <td>    0.811</td> <td>    0.385</td> <td> 0.701</td> <td>   -1.291</td> <td>    1.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NFT</th>                <td>    0.1146</td> <td>    0.149</td> <td>    0.771</td> <td> 0.442</td> <td>   -0.179</td> <td>    0.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Haptic)[T.1]:NFT</th> <td>   -0.0169</td> <td>    0.192</td> <td>   -0.088</td> <td> 0.930</td> <td>   -0.396</td> <td>    0.363</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.395</td> <th>  Durbin-Watson:     </th> <td>   1.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  10.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.527</td> <th>  Prob(JB):          </th> <td> 0.00647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.338</td> <th>  Cond. No.          </th> <td>    41.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      PurchaseIntention   R-squared:                       0.067\n",
       "Model:                            OLS   Adj. R-squared:                  0.017\n",
       "Method:                 Least Squares   F-statistic:                     1.327\n",
       "Date:                Tue, 30 Nov 2021   Prob (F-statistic):              0.234\n",
       "Time:                        14:48:24   Log-Likelihood:                -276.73\n",
       "No. Observations:                 156   AIC:                             571.5\n",
       "Df Residuals:                     147   BIC:                             598.9\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept              3.5707      0.632      5.649      0.000       2.322       4.820\n",
       "C(Age)[T.3]           -0.0898      0.329     -0.273      0.785      -0.740       0.560\n",
       "C(Age)[T.5]           -0.3224      0.449     -0.719      0.474      -1.209       0.564\n",
       "C(Age)[T.6]           -0.7381      0.405     -1.822      0.070      -1.539       0.062\n",
       "C(Age)[T.7]            0.9107      0.762      1.195      0.234      -0.596       2.417\n",
       "C(Gender)[T.2]         0.4197      0.268      1.564      0.120      -0.111       0.950\n",
       "C(Haptic)[T.1]         0.3119      0.811      0.385      0.701      -1.291       1.915\n",
       "NFT                    0.1146      0.149      0.771      0.442      -0.179       0.408\n",
       "C(Haptic)[T.1]:NFT    -0.0169      0.192     -0.088      0.930      -0.396       0.363\n",
       "==============================================================================\n",
       "Omnibus:                       12.395   Durbin-Watson:                   1.893\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               10.083\n",
       "Skew:                          -0.527   Prob(JB):                      0.00647\n",
       "Kurtosis:                       2.338   Cond. No.                         41.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapticDF = df[Q1_HighNFTHoodie].loc[2:]\n",
    "NonhapticDF = df[Q1_LowNFTHoodie].loc[2:]\n",
    "hapticDF2 = df[Q2_HighNFTHoodie].loc[2:]\n",
    "NonhapticDF2 = df[Q2_LowNFTHoodie].loc[2:]\n",
    "\n",
    "OLSdf_Nonhaptic = NonhapticDF\n",
    "OLSdf_Nonhaptic['Age'] = df['Q22'].loc[1:]\n",
    "OLSdf_Nonhaptic['Gender'] = df['Q113'].loc[1:]\n",
    "\n",
    "OLSdf_Nonhaptic['Haptic'] = 0\n",
    "\n",
    "OLSdf_Nonhaptic['NFT'] = df['NFT_score'].loc[1:]\n",
    "\n",
    "full_list = []\n",
    "\n",
    "for index in OLSdf_Nonhaptic.index:\n",
    "    for column in ['Q91','Q54','Q90','Q77']:\n",
    "        alist = [OLSdf_Nonhaptic[column].loc[index], OLSdf_Nonhaptic['Haptic'].loc[index] , OLSdf_Nonhaptic['NFT'].loc[index], OLSdf_haptic['Gender'].loc[index], OLSdf_haptic['Age'].loc[index]]\n",
    "        full_list.append(alist)\n",
    "        \n",
    "OLSdfNH = pd.DataFrame.from_records(full_list, columns=['PurchaseIntention', 'Haptic', 'NFT', 'Gender', 'Age'])\n",
    "\n",
    "OLSdfNH = OLSdfNH[OLSdfNH['PurchaseIntention'].notna()]\n",
    "\n",
    "\n",
    "OLSdf_haptic = hapticDF\n",
    "OLSdf_haptic['Age'] = df['Q22'].loc[1:]\n",
    "OLSdf_haptic['Gender'] = df['Q113'].loc[1:]\n",
    "\n",
    "OLSdf_haptic['Haptic'] = 1\n",
    "\n",
    "OLSdf_haptic['NFT'] = df['NFT_score'].loc[1:]\n",
    "\n",
    "full_list = []\n",
    "\n",
    "for index in OLSdf_haptic.index:\n",
    "    for column in ['Q107','Q40','Q32','Q70']:\n",
    "        alist = [OLSdf_haptic[column].loc[index], OLSdf_haptic['Haptic'].loc[index] , OLSdf_haptic['NFT'].loc[index], OLSdf_haptic['Gender'].loc[index], OLSdf_haptic['Age'].loc[index]]\n",
    "        full_list.append(alist)\n",
    "        \n",
    "OLSdfHH = pd.DataFrame.from_records(full_list, columns=['PurchaseIntention', 'Haptic', 'NFT', 'Gender', 'Age'])\n",
    "\n",
    "OLSdfHH = OLSdfHH[OLSdfHH['PurchaseIntention'].notna()]\n",
    "\n",
    "result = pd.concat([OLSdfHH, OLSdfNH])\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "for column in result.columns:\n",
    "    result[column] = pd.to_numeric(result[column])\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "#mod = smf.ols(\"Purchase Intention ~ C(Haptic):(NFT)\", data=result).fit()\n",
    "\n",
    "fit = ols('PurchaseIntention ~ C(Haptic)', data=result[['PurchaseIntention', 'Haptic']]).fit()\n",
    "fit2 = ols(\"PurchaseIntention ~ NFT\", data=result).fit()\n",
    "fit3 = ols(\"PurchaseIntention ~ C(Haptic):(NFT)\", data=result).fit()\n",
    "fit4 = ols(\"PurchaseIntention ~ C(Age) + C(Gender) + C(Haptic) + NFT + C(Haptic):(NFT)\", data=result).fit()\n",
    "\n",
    "fit4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
